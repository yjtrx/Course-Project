{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project - R8 - Statistical NLP - Blog Authorship Corpus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "17pz9K8yoWZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "820f3834-4e76-4233-c057-7a9830b64876"
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC3uu7NOoWWU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50361bc7-396e-404f-9ca7-5f28a31e4fb6"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEuT_qWdoWUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"yjtrxj\",\"key\":\"131bbafb775c8139a4bb07dbc9427ac7\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx_z_QL4oWR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvHxkQtFoWPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "132108c4-0cdf-4008-aca9-fef85b5c29a2"
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6dxNguYoWNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUuDSPOToWLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "1b7ecbfd-dbc1-4942-f8e2-abe9aea8748d"
      },
      "source": [
        "!kaggle datasets list -s blog"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/cli.py\", line 51, in main\n",
            "    out = args.func(**command_args)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 910, in dataset_list_cli\n",
            "    tag_ids, search, user, mine, page)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 880, in dataset_list\n",
            "    return [Dataset(d) for d in datasets_list_result]\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/models/kaggle_models_extended.py\", line 66, in __init__\n",
            "    self.size = File.get_size(self.totalBytes)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/models/kaggle_models_extended.py\", line 97, in get_size\n",
            "    return '%.*f%s' % (precision, size, suffixes[suffix_index])\n",
            "TypeError: float argument required, not NoneType\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qICqPMqzoWJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "883dbd60-fc4f-4151-dcbc-aed3a804dc70"
      },
      "source": [
        "!kaggle datasets download -d rtatman/blog-authorship-corpus -p /content/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading blog-authorship-corpus.zip to /content\n",
            " 95% 274M/290M [00:02<00:00, 107MB/s]\n",
            "100% 290M/290M [00:03<00:00, 97.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GLtTopYoy0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "53673dc7-f7c8-4e39-ee53-a1f52cff620c"
      },
      "source": [
        "!unzip \\blog-authorship-corpus.zip"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  blog-authorship-corpus.zip\n",
            "  inflating: blogtext.csv            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_cl6JBgmZt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "blog = pd.read_csv('blogtext.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ9jrlrHov_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#blog_df = blog.sample(frac =0.012,replace=False,random_state=5678)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu_PPKR9OIg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blog_df = blog.iloc[:8000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0bb46ynmjqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c82ebd39-ee3d-47ea-8a82-ccf1b4cae128"
      },
      "source": [
        "blog_df.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TPTORDmmjmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "fb9846c1-0c27-4743-ac5e-39d769a2704c"
      },
      "source": [
        "blog_df.isnull().sum()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "gender    0\n",
              "age       0\n",
              "topic     0\n",
              "sign      0\n",
              "date      0\n",
              "text      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwF0U-Srmjky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "d7056dc3-23a8-47c8-fee8-094f503424cc"
      },
      "source": [
        "blog_df['text'].unique()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['           Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.         ',\n",
              "       '           These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail          ',\n",
              "       \"           In het kader van kernfusie op aarde:  MAAK JE EIGEN WATERSTOFBOM   How to build an H-Bomb From: ascott@tartarus.uwa.edu.au (Andrew Scott) Newsgroups: rec.humor Subject: How To Build An H-Bomb (humorous!) Date: 7 Feb 1994 07:41:14 GMT Organization: The University of Western Australia  Original file dated 12th November 1990. Seemed to be a transcript of a 'Seven Days' article. Poorly formatted and corrupted. I have added the text between 'examine under a microscope' and 'malleable, like gold,' as it was missing. If anyone has the full text, please distribute. I am not responsible for the accuracy of this information. Converted to HTML by Dionisio@InfiNet.com 11/13/98. (Did a little spell-checking and some minor edits too.) Stolen from  urlLink http://my.ohio.voyager.net/~dionisio/fun/m...own-h-bomb.html  and reformatted the HTML. It now validates to XHTML 1.0 Strict. How to Build an H-Bomb Making and owning an H-bomb is the kind of challenge real Americans seek. Who wants to be a passive victim of nuclear war when, with a little effort, you can be an active participant? Bomb shelters are for losers. Who wants to huddle together underground eating canned Spam? Winners want to push the button themselves. Making your own H-bomb is a big step in nuclear assertiveness training -- it's called Taking Charge. We're sure you'll enjoy the risks and the heady thrill of playing nuclear chicken. Introduction When the Feds clamped down on The Progressive magazine for attempting to publish an article on the manufacture of the hydrogen bomb, it piqued our curiosity. Was it really true that atomic and hydrogen bomb technology was so simple you could build an H-bomb in your own kitchen? Seven Days decided to find out. Food editor Barbara Ehrenreich, investigative reporter Peter Biskind, Photographer Jane Melnick and nuclear scientist Michio Kaku were given three days to cook up a workable H-bomb. They did and we have decided to share their culinary secrets with you. Not that Seven Days supports nuclear terrorism. We don't. We would prefer to die slowly from familiar poisons like low-level radiation, microwaves, DDT, DBCP, aflatoxins, PBBs, PBCs, or food dyes, rather than unexpectedly, say as hostage to a Latvian nationalist brandishing a homemade bomb. In our view the real terrorists are the governments, American, Soviet, French, Chinese, and British, that are hoarding H-bombs for their own use, and worse still, those governments (U.S., French and German) that are eagerly peddling advanced nuclear technology to countries like South Africa, Brazil, and Argentina so that they can make their own bombs. When these bombs are used, and they will be, it will be the world's big-time nuclear peddlers, along with corporate suppliers like General Electric, Westinghouse, and Gulf Oil, that we can thank for it. Gagging The Progressive will do no more for national security than backyard bomb shelters because like it or not the news is out. The heart of the successful H-bomb is the successful A-bomb. Once you've got your A-bombs made the rest is frosting on the cake. All you have to do is set them up so that when they detonate they'll start off a hydrogen-fusion reaction.  Part 1: Making Your Bomb Step 1: Getting the Ingredients Uranium is the basic ingredient of the A-bomb. When a uranium atom's nucleus splits apart, it releases a tremendous amount of energy (for its size), and it emits neutrons which go on to split other nearby uranium nuclei, releasing more energy, in what is called a 'chain reaction'. (When atoms split, matter is converted into energy according to Einstein's equation E=MC2. What better way to mark his birthday than with your own atomic fireworks?) There are two kinds (isotopes) of uranium: the rare U-235, used in bombs, and the more common, heavier, but useless U-238. Natural uranium contains less than 1 percent U-235 and in order to be usable in bombs it has to be 'enriched' to 90 percent U-235 and only 10 percent U-238. Plutonium-239 can also be used in bombs as a substitute for U-235. Ten pounds of U-235 (or slightly less plutonium) is all that is necessary for a bomb. Less than ten pounds won't give you a critical mass. So purifying or enriching naturally occurring uranium is likely to be your first big hurdle. It is infinitely easy to steal ready-to-use enriched uranium or plutonium than to enrich some yourself. And stealing uranium is not as hard as it sounds. There are at least three sources of enriched uranium or plutonium... Enriched uranium is manufactured at a gaseous diffusion plant in Portsmouth, Ohio. From there it is shipped in 10 liter bottles by airplane and trucks to conversion plants that turn it into uranium oxide or uranium metal. Each 10 liter bottle contains 7 kilograms of U-235, and there are 20 bottles to a typical shipment. Conversion facilities exist at Hematite, Missouri; Apollo, Pennsylvania; and Erwin, Tennessee. The Kerr-McGee plant at Crescent Oklahoma -- where Karen Silkwood worked -- was a conversion plant that 'lost' 40 lbs of plutonium. Enriched uranium can be stolen from these plants or from fuel-fabricating plants like those in New Haven, San Diego; or Lynchburg, Virginia. (A former Kerr-McGee supervisor, James V. Smith, when asked at the Silkwood trial if there were any security precautions at the plant to prevent theft, testified that 'There were none of any kind, no guards, no fences, no nothing.') Plutonium can be obtained from places like United Nuclear in Pawling, New York; Nuclear Fuel Services in Erwin, Tennessee; General Electric in Pleasanton, California; Westinghouse in Cheswick, Pennsylvania; Nuclear Materials and Equipment Corporation (NUMEC) in Leechburg, Pennsylvania; and plants in Hanfford, Washington and Morris, Illinois. According to Rolling Stone magazine the Israelis were involved in the theft of plutonium from NUMEC. Finally you can steal enriched uranium or plutonium while it's en-route from conversion plants to fuel fabricating plants. It is usually transported (by air or truck) in the form of uranium oxide, a brownish powder resembling instant coffee, or as a metal, coming in small chunks called 'broken buttons.' Both forms are shipped in small cans stacked in 5-inch cylinders braced with welded struts in the center of ordinary 55 gallon steel drums. The drums weigh about 100 pounds and are clearly marked 'Fissible Material' or 'Danger, Plutonium.' A typical shipment might go from the enrichment plant at Portsmouth, Ohio to the conversion plant in Hematite Missouri then to Kansas City by truck where it would be flown to Los Angeles and then trucked down to the General Atomic plant in San Diego. The plans for the General Atomic plant are on file at the Nuclear Regulatory Commission's reading room at 1717 H Street NW Washington. A Xerox machine is provided for the convenience of the public. If you can't get hold of any enriched uranium you'll have to settle for commercial grade (20 percent U-235). This can be stolen from university reactors of a type called TRIGA Mark II, where security is even more casual than at commercial plants. If stealing uranium seems too tacky you can buy it. Unenriched uranium is available at any chemical supply house for $23 a pound. Commercial grade (3 to 20 percent enriched) is available for $40 a pound from Gulf Atomic. You'll have to enrich it further yourself. Quite frankly this can be something of a pain in the ass. You'll need to start with a little more than 50 pounds of commercial-grade uranium. (It's only 20 percent U-235 at best, and you need 10 pounds of U-235 so... ) But with a little kitchen-table chemistry you'll be able to convert the solid uranium oxide you've purchased into a liquid form. Once you've done that, you'll be able to separate the U-235 that you'll need from the U-238. First pour a few gallons of concentrated hydrofluoric acid into your uranium oxide, converting it to uranium tetrafluoride. (Safety note: Concentrated hydrofluoric acid is so corrosive that it will eat its way through glass, so store it only in plastic. Used 1-gallon plastic milk containers will do.) Now you have to convert your uranium tetrafluoride to uranium hexafluoride, the gaseous form of uranium, which is convenient for separating out the isotope U-235 from U-238. To get the hexafluoride form, bubble fluorine gas into your container of uranium tetrafluoride. Fluorine is available in pressurized tanks from chemical-supply firms. Be careful how you use it though because fluorine is several times more deadly than chlorine, the classic World War I poison gas. Chemists recommend that you carry out this step under a stove hood (the kind used to remove unpleasant cooking odors). If you've done your chemistry right you should now have a generous supply of uranium hexafluoride ready for enriching. In the old horse-and-buggy days of A-bomb manufacture the enrichment was carried out by passing the uranium hexafluoride through hundreds of miles of pipes, tubes, and membranes, until the U-235 was eventually separated from the U-238. This gaseous-diffusion process, as it was called is difficult, time-consuming, and expensive. Gaseous-diffusion plants cover hundreds of acres and cost in the neighborhood of $2-billion each. So forget it. There are easier, and cheaper, ways to enrich your uranium. First transform the gas into a liquid by subjecting it to pressure. You can use a bicycle pump for this. Then make a simple home centrifuge. Fill a standard-size bucket one-quarter full of liquid uranium hexafluoride. Attach a six-foot rope to the bucket handle. Now swing the rope (and attached bucket) around your head as fast as possible. Keep this up for about 45 minutes. Slow down gradually, and very gently put the bucket on the floor. The U-235, which is lighter, will have risen to the top, where it can be skimmed off like cream. Repeat this step until you have the required 10 pounds of uranium. (Safety note: Don't put all your enriched uranium hexafluoride in one bucket. Use at least two or three buckets and keep them in separate corners of the room. This will prevent the premature build-up of a critical mass.) Now it's time to convert your enriched uranium back to metal form. This is easily enough accomplished by spooning several ladlefuls of calcium (available in tablet form from your drugstore) into each bucket of uranium. The calcium will react with the uranium hexafluoride to produce calcium fluoride, a colorless salt which can be easily be separated from your pure enriched uranium metal. A few precautions: • While uranium is not dangerously radioactive in the amounts you'll be handling, if you plan to make more than one bomb it might be wise to wear gloves and a lead apron, the kind you can buy in dental supply stores. • Plutonium is one of the most toxic substances known. If inhaled, a thousandth of a gram can cause massive fibrosis of the lungs, a painful way to go. Even a millionth of a gram in the lungs will cause cancer. If eaten plutonium is metabolized like calcium. It goes straight to the bones where it gives out alpha particles preventing bone marrow from manufacturing red blood cells. The best way to avoid inhaling plutonium is to hold your breath while handling it. If this is too difficult wear a mask. To avoid ingesting plutonium orally follow this simple rule: never make an A-bomb on an empty stomach. • If you find yourself dozing off while you're working, or if you begin to glow in the dark, it might be wise to take a blood count. Prick your finger with a sterile pin, place a drop of blood on a microscope slide, cover it with a cover slip, and examine under a microscope. (Best results are obtained in the early morning.) When you get leukemia, immature cells are released into the bloodstream, and usually the number of white cells increases (though this increase might take almost 2 weeks). Red blood cells look kind of like donuts (without the hole), and are slightly smaller than the white cells, each of which has a nucleus. Immature red cells look similar to white cells (i.e.. slightly larger and have a nucleus). If you have more than about 1 white cell (including immature ones) to 400 red cells then start to worry. But, depending upon your plans for the eventual use of the bomb, a short life expectancy might not be a problem.  Step 2: Assembling the A-Bomb Now that you've acquired the enriched uranium, all that's left is to assemble your A-bomb. Go find a couple of stainless steel salad bowls. You also want to separate your 10 pounds of U-235 into two hunks. (Keep them apart!) The idea is to push each half your uranium into the inside of a bowl. Take one hunk of your uranium and beat it into the inside of the first bowl. Uranium is malleable, like gold, so you should have no trouble hammering it into the bowl to get a good fit. Take another five-pound hunk of uranium and fit it into a second stainless steel bowl. These two bowls of U-235 are the 'subcritical masses' which, when brought together forcefully, will provide the critical mass that makes your A-bomb go. Keep them a respectful distance apart while working because you don't want them to 'go critical' on you... At least not yet. Now hollow out the body of an old vacuum cleaner and place your two hemispherical bowls inside, open ends facing each other, no less than seven inches apart, using masking tape to set them up in position. The reason for the steel bowls and the vacuum cleaner, in case you're wondering, is that these help reflect the neutrons back into the uranium for a more efficient explosion. 'A loose neutron is a useless neutron' as the A-bomb pioneers used to say. As far as the A-bomb goes, you're almost done. The final problem is to figure out how to get the two U-235 hemispheres to smash into each other with sufficient force to set off a truly effective fission reaction. Almost any type of explosive can be used to drive them together. Gunpowder, for example, is easily made at home from potassium nitrate, sulfur, and carbon. Or, you can get some blasting caps or TNT. (Buy them or steal them from a construction site.) Best of all is C4 plastic explosive. You can mold it around your bowls, and it's fairly safe to work with. (But, it might be wise to shape it around an extra salad bowl in another room, and THEN fit it to your uranium-packed bowls. This is particularly true in winter, when a stray static electrical charge might induce ignition in the C4. A responsible bomb maker considers it impolite to accidentally destroy more of the neighborhood than absolutely necessary.) Once the explosives are in place all you need to do is hook up a simple detonation device with a few batteries, a switch, and some wire. Remember though that it is essential that the two charges -- one on each side of the casing -- go off simultaneously. Now put the whole thing in the casing of an old Hoover vacuum cleaner and you're finished with this part of the process. The rest is easy.  Step 3: Make More A-Bombs Following the Directions Above  A Word to the Wise About Wastes After your A-bomb is completed you'll have a pile of moderately fatal radioactive wastes like U-238. These are not dangerous, but you do have to get rid of them. You can flush leftovers down the toilet. (Don't worry about polluting the ocean, there is already so much radioactive waste there, a few more bucketfuls won't make any waves whatsoever.) If you're the fastidious type -- the kind who never leaves gum under their seat at the movies -- you can seal the nasty stuff in coffee cans and bury it in the backyard, just like Uncle Sam does. If the neighbor kids have a habit of trampling the lawn, tell them to play over by the waste. You'll soon find that they're spending most of their time in bed.  Going First Class If you're like us, you're feeling the economic pinch, and you'll want to make your bomb as inexpensively as possible, consonant of course with reasonable yield. The recipe we've given is for a budget-pleasing H-bomb, no frills, no flourishes; it's just a simple 5-megaton bomb, capable of wiping out the New York metropolitan area, the San Francisco Bay area, or Boston. But don't forget, your H-bomb will only be as good as the A-bombs in it. If you want to spend a little more money you can punch-up your A-bomb considerably. Instead of centrifuging your uranium by hand, you can buy a commercial centrifuge. (Fisher Scientific sells one for about $1000.) You also might want to be fussier about your design. The Hiroshima bomb, a relatively crude one, only fissioned 1 percent of it's uranium and yielded only 13 kilotons. In order to fission more of the uranium, the force of your explosive 'trigger' needs to be evenly diffused around the sphere; the same pressure has to be exerted on every point of the sphere simultaneously. (It was a technique for producing this sort of simultaneous detonation by fashioning the explosives into lenses that the government accused Julius and Ethel Rosenberg of trying to steal).  Part 2: Putting Your H-Bomb Together The heart of the H-bomb is the fusion process. Several A-bombs are detonated in such a way as to create the extremely high temperature (100 million degrees C) necessary to fuse lithium deuteride (LiD) into helium. When the lithium nucleus slams into the deuterium nucleus, two helium nuclei are created, and if this happens to enough deuterium nuclei rapidly enough, the result is an enormous amount of energy: the energy of the H-bomb. You don't have to worry about stealing lithium deuteride, it can be purchased from any chemical-supply house. It costs $1000 a pound. If your budget won't allow it you can substitute lithium hydride at $40 a pound. You will need at least 100 pounds. It's a corrosive and toxic powder so be careful. Place the lithium deuteride or hydride in glass jars and surround it with four A-bombs in their casings. Attach them to the same detonator so that they will go off simultaneously. The container for the whole thing is no problem. They can be placed anywhere: Inside an old stereo console, a discarded refrigerator, etc... When the detonator sets off the four A-bombs all eight hemispheres of fissionable material will slam into each other at the same time creating four critical masses and four detonations. This will raise the temperature of the lithium deuteride to 100 million degrees C fast enough (a few billionths of a second) so that the lithium will not be blown all over the neighborhood before the nuclei have time to fuse. The result, at least 1000 times the punch of the puny A-bomb that leveled Hiroshima (20 million tons of TNT vs. 20 thousand tons.)  Part 3: What to do With Your Bomb Now that you have a fully assembled H-bomb housed in an attractive console of your choice you may be wondering, 'What should I do with it?' Every family will have to answer this question according to its own tastes and preferences, but you may want to explore some possibilities which have been successfully pioneered by the American government. 1. Sell Your Bomb and Make a Pile of Money In these days of rising inflation, increasing unemployment, and an uncertain economic outlook, few businesses make as much sense as weapons production. If your career forecast is cloudy, bomb sales may be the only sure way to avoid the humiliation of receiving welfare, or unemployment. Regardless of your present income level, a home H-bomb business can be an invaluable income supplement, and certainly a profitable alternative to selling Tupperware or pirated Girl Scout cookies. Unfortunately for the family bomb business, big government has already cornered a large part of the world market. But this does not mean that there is a shortage of potential customers. The raid on Entebee was the Waterloo of hijacking, and many nationalist groups are now on the alert for new means to get their message across. They'd jump at the chance to get hold of an H-bomb. Emerging nations which can't ante up enough rice or sugar to buy themselves a reactor from G.E. or Westinghouse are also shopping around. You may wonder about the ethics of selling to nations, or groups, whose goals you may disapprove of. But here again, take a tip from our government: forget ideology -- it's cash that counts. And remember, H-bomb sales have a way of escalating, almost like a chain reaction. Suppose you make a sale to South Yemen which you believe to be a Soviet puppet. Well within a few days some discrete inquiries from North Yemen and possibly the Saudis, the Egyptians and the Ethiopians as well can be expected. Similarly, a sale to the IRA will generate a sale to the Ulster government; and a sale to the Tanzanians will bring the Ugandans running, and so forth. It doesn't matter WHICH side you're on, only how many sides there are. Don't forget about the possibility of repeat sales to the same customer. As the experience of both the U.S. and the U.S.S.R. has shown, each individual nation has a potentially infinite need for H-bombs. No customer -- no matter how small -- can ever have too many. 2. Use Your Bomb at Home Many families are attracted to the H-bomb simply as a 'deterrent.' A discrete sticker on the door or on the living room window saying 'This Home Protected by H-bomb' will discourage IRS investigators, census takers, and Jehovah's Witnesses. You'll be surprised how fast the crime rate will go down and property values will go up. And once the news gets out that you are a home H-bomb owner you'll find that you have unexpected leverage in neighborhood disputes over everything from parking places and stereo noise levels to school tax rates. So relax and enjoy the pride and excitement of home H-bomb ownership!  Is It For You? Let's be honest. The H-bomb isn't for everyone. Frankly there are people who can't handle it. They break out in hives at the very mention of mega-death, fallout, or radiation sickness. The following quiz will help you find out whether you have what it takes for home H-bomb ownership. If you can answer 'yes' to six or more of these questions, then you're emotionally eligible to join the nuclear club. If not, a more conventional weapon may be more your cup of tea, try botulism-toxin, laser rays, or nerve gas. 1. I ignore the demands of others. 2. I subscribe to one or more of the following: Soldier of Fortune, Hustler, Popular Mechanics, Self. 3. Though I have many interesting acquaintances, I am my own best friend. 4. I know what to say after you say 'Hello,' but I am seldom interested in pursuing the conversation. 5. I have seen the movie 'The Deer Hunter' more than once. 6. I know that everyone can be a winner if they want to, and I resent whiners. 7. I own one or more of the following: handgun, video game, trash compactor, snowmobile. 8. I am convinced that leukemia is psychosomatic. 9. I am aware that most vegetarians are sexually impotent. 10. I have read evidence that solar energy is a Communist conspiracy.  Myths About Nuclear War Ever since the first mushroom cloud over Hiroshima ushered in the atomic age, a small group of nay-sayers and doom-mongers has lobbied, campaigned and demonstrated to convince Americans that H-bomb ownership, along with nuclear power, is dangerous and unhealthy. Using their virtual stranglehold over the media, these people have tried to discredit everything nuclear from energy to war. They have vastly overrated the risks of nuclear bombs and left many Americans feeling demoralized and indecisive; not sure where the truth lies. Well, here are the myths, and here are the facts. Myth: After a nuclear exchange the earth will no longer be suitable for human habitation. Fact: This is completely false. According to one scientist (quoted in John McPee's The Curve of Binding Energy) 'The largest bomb that has ever been exploded anywhere was 60 megatons, and that is one-thousandth the force of an earthquake, one-thousandth the force of a hurricane. We have lived with earthquakes and hurricanes for a long time.' Another scientist adds, 'It is often assumed that a full blown nuclear war would be the end of life on earth. That is far from the truth. To end life on earth would take at least a thousand times the total yield of all the nuclear explosives existing in the world, and probably a lot more.' Even if humans succumbed, many forms of life would survive a nuclear free-for-all, cockroaches, certain forms of bacteria, and lichens, for instance. Myth: Radiation is bad for you. Fact: Everything is bad for you if you have too much of it. If you eat too many bananas you'll get a stomach-ache. If you get too much sun you can get sunburned (or even skin cancer). Same thing with radiation. Too much may make you feel under the weather, but nuclear industry officials insist that there is no evidence that low-level radiation has any really serious adverse effects. And, high-level radiation may bring unexpected benefits. It speeds up evolution by weeding out unwanted genetic types and creating new ones. (Remember the old saying, 'Two heads are better than one.') Nearer to home, it's plain that radiation will get rid of pesky crab grass and weeds, and teenagers will find that brief exposure to a nuclear burst vaporizes acne and other skin blemishes. (Many survivors of the Hiroshima bomb found that they were free from skin and it's attendant problems forever.) We hope this clears up any misconceptions you may have had. Enjoy your H-Bomb!           \",\n",
              "       ...,\n",
              "       \"       Well, my day was...okay, average, long, tired.....blaa.  Well, Erica is feeling better. Yeah!  Ooo!  I told Lindsay how we thought it would be cool if Michael played Juliet for Shakespeare with Medlin.  I think she wanted to be Juliet.  Oh I have good news for those who care.  My foot is healing, it's itchy and I think scabbing.  Oh man I am so tired!  We have shortened classes tomorrow for a suckey assembly on bullying called Bang Bang You're Dead.  Sounds Oscar worthy. Well that's about it for today.  sea you guys tomorrow           \",\n",
              "       \"       Sorry for the title.  It was more like a comment and has nothing to do with this entry!  Anyway....Interp practice today rocked my socks off!  We have our music and learned from now on we are practicing on the stage!  How exciting!!  And....that Friday on the 26th we get to miss the whole day of school!!!!!!!!!  I am super psyched.  We will be practicing at Elisa's that morning and compete at around 1:00 at Ravenwood.  Whoo Hoo!!  As you can see I am super super excited (doesn't that sound like an Elle Woods line).  Ha! I crack myself up with my exclamation point rampage!  And I going out tonight to get my hoodie.  I am a blessed person!  Well enough for now!  If you read comment, Pleeeease!  P.S.  Becca you should really start your own blog.  Since I have refused to read Jenessa's and Liz's I only have Erica's to read.         \",\n",
              "       \"       READY FOR LOVE: You're sensitive but no pushover, active but not manic. In short, you're a great girl/guy who's ready for a relationship. If you're not already involved with someone, it's only because you want a guy/girl who's worthy of your love---you just haven't met him/her yet. That's cool. You've got plenty of other interests to keep you busy. When you do meet ''Mr. Great/Miss. Great,'' chances are you won't abandon all the other impotant stuff in your life for romance. In fact, your independance and spirit will be part of what attracts him/her---and keeps him/her. Would YOU PLEASE rate my quiz? YOU surely don't have to, but i'd apreciate it more than YOU could imagine if YOU would! Thanks! Peace out yo'!        urlLink Are YOU ready to have a BOYFRIEND/GIRLFRIEND? For the OLDER GALS/GUYS!      brought to you by  urlLink Quizilla    M&M'S: Just like the candy. you're soft on the inside, but have a protective shell so you don't melt for all things sentimental. While you're not going to forget what's important to you (like friends, school and the cool activities that make you such an interesting girl), you're also open to romance in whatever form it might take. You'll have an amazing V-Day, whether you spend it with a cute boy or have a girls night out. Would YOU PLEASE rate my quiz? Thanks a whole bunch!     urlLink How ROMANTIC are YOU? For the LADiES!     brought to you by  urlLink Quizilla    THE FREETHINKINER: I like you, and I don't even know you. Who wouldn't? You have your own opinions---and are confident enough to voice them---but you're also willing to listen to the other side. And you're not afraid to try new stuff even when your friends aren't interested. For example, if you were dying to see Linkin Park in concert and no one else wanted to go, you'd still be there rockin' out. Basically, you rule.     urlLink How INDEPEDNDANT are YOU? (For the LADIES!)     brought to you by  urlLink Quizilla             \"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCVZHN0omjgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "451e703a-6287-4820-b6b9-5f1427aab611"
      },
      "source": [
        "blog_df.info()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8000 entries, 0 to 7999\n",
            "Data columns (total 7 columns):\n",
            "id        8000 non-null int64\n",
            "gender    8000 non-null object\n",
            "age       8000 non-null int64\n",
            "topic     8000 non-null object\n",
            "sign      8000 non-null object\n",
            "date      8000 non-null object\n",
            "text      8000 non-null object\n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 437.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ_14Zz0mjeQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c80de7c0-dab7-488a-8d72-fc15c1dd4cf6"
      },
      "source": [
        "blog_df['label'] = blog_df.apply(lambda r: [r['gender'], str(r['age']), r['topic'],r['sign']], axis=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtAX4rotnIqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0d16b678-e1ef-4755-9b21-c36138df7a13"
      },
      "source": [
        "blog_df.drop(columns=['id','gender','age','topic','sign','date'],inplace = True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pb3aeC7e_7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "56e6ffd2-fb27-4da0-9b22-13a099b8089a"
      },
      "source": [
        "blog_df.head(2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Info has been found (+/- 100 pages,...</td>\n",
              "      <td>[male, 15, Student, Leo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>These are the team members:   Drewe...</td>\n",
              "      <td>[male, 15, Student, Leo]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                     label\n",
              "0             Info has been found (+/- 100 pages,...  [male, 15, Student, Leo]\n",
              "1             These are the team members:   Drewe...  [male, 15, Student, Leo]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3665lVnmjZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "893c8f16-087d-416a-e500-20efc990cb55"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "blog_df['text'] = blog_df['text'].map(lambda s : s.lower())\n",
        "blog_df['text'] = blog_df['text'].map(lambda s:re.sub('[0-9+-/#()!:\\']','',s))\n",
        "blog_df['text'] = blog_df['text'].map(lambda s :s.strip())\n",
        "sw = stopwords.words('english')\n",
        "blog_df['text'] = blog_df['text'].apply(lambda s: ' '.join([word for word in s.split() if word not in (sw)]))\n",
        "blog_df['text']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       info found pages mb pdf files wait untill team...\n",
              "1       team members drewes van der laag urllink mail ...\n",
              "2       het kader van kernfusie op aarde maak je eigen...\n",
              "3                                         testing testing\n",
              "4       thanks yahoos toolbar capture urls popupswhich...\n",
              "                              ...                        \n",
              "7995    today good excellent time warming becca downlo...\n",
              "7996    oh goodness oh goodness oh goodness best news ...\n",
              "7997    well day wasokay average long tiredblaa well e...\n",
              "7998    sorry title like comment nothing entry anywayi...\n",
              "7999    ready love youre sensitive pushover active man...\n",
              "Name: text, Length: 8000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWX013almjX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = blog_df.text\n",
        "y = blog_df.label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1GayGRHmjVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#you can change the test size & a smaller train size will help your system to fit in count vectorizer otherwise system will crash\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu4nJUiGqrLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_CbLtusmjTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "081f6c7d-8daf-405f-f37e-3be50265c3f2"
      },
      "source": [
        "print(\"X_train shape is : \",x_train.shape)\n",
        "print(\"X_test shape is : \",x_test.shape)\n",
        "print(\"X_val shape is : \",x_val.shape)\n",
        "print(\"y_train shape is : \",y_train.shape)\n",
        "print(\"y_test shape is : \",y_test.shape)\n",
        "print(\"y_val shape is : \",y_val.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape is :  (4480,)\n",
            "X_test shape is :  (1600,)\n",
            "X_val shape is :  (1920,)\n",
            "y_train shape is :  (4480,)\n",
            "y_test shape is :  (1600,)\n",
            "y_val shape is :  (1920,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbwrbAk1mjRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xppRrmTjmjPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer(ngram_range=(1,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y79ImwhmjNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = cv.fit_transform(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjXjx9zDmjLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = cv.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwYNgCmN7qQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = cv.transform(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDRFKXU7mjJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "outputId": "27e6577c-991c-4735-a9be-fe6b528a0611"
      },
      "source": [
        "#just to check the\n",
        "print(x_val)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 22939)\t1\n",
            "  (0, 94487)\t2\n",
            "  (0, 95572)\t1\n",
            "  (1, 60860)\t1\n",
            "  (1, 132961)\t1\n",
            "  (1, 177871)\t1\n",
            "  (1, 195379)\t1\n",
            "  (1, 195682)\t1\n",
            "  (1, 197845)\t1\n",
            "  (1, 203340)\t1\n",
            "  (1, 226028)\t1\n",
            "  (1, 231364)\t1\n",
            "  (1, 244436)\t1\n",
            "  (1, 244610)\t1\n",
            "  (1, 255791)\t1\n",
            "  (1, 255867)\t1\n",
            "  (1, 278485)\t2\n",
            "  (2, 9807)\t3\n",
            "  (2, 9821)\t1\n",
            "  (2, 11789)\t1\n",
            "  (2, 14326)\t1\n",
            "  (2, 14445)\t1\n",
            "  (2, 19585)\t1\n",
            "  (2, 24251)\t2\n",
            "  (2, 24271)\t2\n",
            "  :\t:\n",
            "  (1919, 256030)\t1\n",
            "  (1919, 257412)\t1\n",
            "  (1919, 258198)\t1\n",
            "  (1919, 259731)\t1\n",
            "  (1919, 262013)\t3\n",
            "  (1919, 262463)\t1\n",
            "  (1919, 264015)\t1\n",
            "  (1919, 264034)\t1\n",
            "  (1919, 266474)\t2\n",
            "  (1919, 269351)\t1\n",
            "  (1919, 270501)\t1\n",
            "  (1919, 272525)\t1\n",
            "  (1919, 273148)\t1\n",
            "  (1919, 273329)\t1\n",
            "  (1919, 275114)\t1\n",
            "  (1919, 281242)\t1\n",
            "  (1919, 281507)\t1\n",
            "  (1919, 281549)\t1\n",
            "  (1919, 288870)\t1\n",
            "  (1919, 288871)\t1\n",
            "  (1919, 289634)\t1\n",
            "  (1919, 296894)\t2\n",
            "  (1919, 300798)\t1\n",
            "  (1919, 301008)\t1\n",
            "  (1919, 301166)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv5XPvTUmjcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_counts = dict()\n",
        "for labels in blog_df.label.values:\n",
        "    for label in labels:\n",
        "        if label in label_counts:\n",
        "            label_counts[label] += 1\n",
        "        else:\n",
        "            label_counts[label] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAgrqgMhnC0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fab9f99-4287-46d2-9cfa-c4b9f3d0dd01"
      },
      "source": [
        "label_counts"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'13': 9,\n",
              " '14': 170,\n",
              " '15': 390,\n",
              " '16': 73,\n",
              " '17': 914,\n",
              " '23': 144,\n",
              " '24': 378,\n",
              " '25': 268,\n",
              " '26': 112,\n",
              " '27': 691,\n",
              " '33': 101,\n",
              " '34': 540,\n",
              " '35': 2311,\n",
              " '36': 1703,\n",
              " '37': 19,\n",
              " '38': 46,\n",
              " '39': 79,\n",
              " '41': 14,\n",
              " '42': 14,\n",
              " '44': 3,\n",
              " '45': 14,\n",
              " '46': 7,\n",
              " 'Accounting': 2,\n",
              " 'Aquarius': 351,\n",
              " 'Aries': 4140,\n",
              " 'Arts': 31,\n",
              " 'Automotive': 14,\n",
              " 'Banking': 16,\n",
              " 'BusinessServices': 87,\n",
              " 'Cancer': 238,\n",
              " 'Capricorn': 88,\n",
              " 'Communications-Media': 61,\n",
              " 'Consulting': 18,\n",
              " 'Education': 121,\n",
              " 'Engineering': 119,\n",
              " 'Fashion': 1616,\n",
              " 'Gemini': 88,\n",
              " 'Internet': 93,\n",
              " 'InvestmentBanking': 70,\n",
              " 'Law': 3,\n",
              " 'Leo': 208,\n",
              " 'Libra': 425,\n",
              " 'Museums-Libraries': 2,\n",
              " 'Non-Profit': 47,\n",
              " 'Pisces': 103,\n",
              " 'Religion': 9,\n",
              " 'Sagittarius': 755,\n",
              " 'Science': 33,\n",
              " 'Scorpio': 854,\n",
              " 'Sports-Recreation': 77,\n",
              " 'Student': 615,\n",
              " 'Taurus': 709,\n",
              " 'Technology': 2350,\n",
              " 'Virgo': 41,\n",
              " 'female': 3061,\n",
              " 'indUnk': 2616,\n",
              " 'male': 4939}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhqCoAV5mjG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f1b18db6-9d70-4d13-860a-2b0585386b3a"
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_train = mlb.fit_transform(y_train)\n",
        "y_test = mlb.transform(y_test)\n",
        "y_val = mlb.transform(y_val)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:987: UserWarning: unknown class(es) ['Law'] will be ignored\n",
            "  .format(sorted(unknown, key=str)))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMdOZx6xT2ng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b98dbf1b-4b7a-4631-a285-1903623ea339"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCSisxn9-tMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13dfd3aa-0886-4cf9-e813-31dea59bc131"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4480, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQmDiGi7mjE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = LogisticRegression(solver='lbfgs',max_iter=10000)\n",
        "clf = OneVsRestClassifier(clf)\n",
        "clfm = OneVsRestClassifier(MultinomialNB())\n",
        "clf0 = GridSearchCV(DecisionTreeClassifier(),cv=5,param_grid={'max_depth':[80,250,500,750,1000]})\n",
        "clf1 = GridSearchCV(KNeighborsClassifier(),cv=5,param_grid={'n_neighbors':[5,10,15,20,25]})\n",
        "clf2 = GridSearchCV(RandomForestClassifier(),cv =5,param_grid={'max_depth':[80,250,500,750,1000]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyekpRmQmjCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "492df0f9-422d-4688-fd70-72b786c053be"
      },
      "source": [
        "%%time\n",
        "clf.fit(x_train,y_train)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 11s, sys: 6min 5s, total: 10min 17s\n",
            "Wall time: 2min 41s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=10000,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='lbfgs', tol=0.0001,\n",
              "                                                 verbose=0, warm_start=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMbfChzDmjAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = clf.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuCAogaomi-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e04d2a32-7e11-4fde-d260-9ccc1bfec42f"
      },
      "source": [
        "from sklearn.metrics import hamming_loss, accuracy_score,classification_report\n",
        "print(\"Model accuracy is:\", clf.score(x_train,y_train))\n",
        "print(\"Accuracy is:\",accuracy_score(y_test,y_pred))\n",
        "print(\"Hamming_loss:\", hamming_loss(y_test, y_pred))\n",
        "report = classification_report(y_test,y_pred)\n",
        "print(report)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy is: 0.9671875\n",
            "Accuracy is: 0.376875\n",
            "Hamming_loss: 0.04161830357142857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.50      0.03      0.05        36\n",
            "           2       0.83      0.26      0.39        93\n",
            "           3       0.00      0.00      0.00        11\n",
            "           4       0.73      0.34      0.46       181\n",
            "           5       1.00      0.02      0.05        42\n",
            "           6       1.00      0.20      0.33        66\n",
            "           7       1.00      0.02      0.03        57\n",
            "           8       0.00      0.00      0.00        19\n",
            "           9       0.61      0.24      0.35       123\n",
            "          10       0.83      0.29      0.43        17\n",
            "          11       1.00      0.59      0.74       108\n",
            "          12       0.73      0.71      0.72       473\n",
            "          13       0.89      0.53      0.66       328\n",
            "          14       0.00      0.00      0.00         7\n",
            "          15       1.00      0.33      0.50         9\n",
            "          16       1.00      0.06      0.11        18\n",
            "          17       0.00      0.00      0.00         3\n",
            "          18       0.00      0.00      0.00         2\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.50      0.11      0.18        71\n",
            "          24       0.77      0.88      0.82       832\n",
            "          25       0.00      0.00      0.00         5\n",
            "          26       0.00      0.00      0.00         5\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       1.00      0.05      0.09        22\n",
            "          29       0.83      0.22      0.35        45\n",
            "          30       0.83      0.26      0.40        19\n",
            "          31       0.00      0.00      0.00        14\n",
            "          32       0.00      0.00      0.00         3\n",
            "          33       0.00      0.00      0.00        23\n",
            "          34       0.57      0.25      0.35        16\n",
            "          35       0.91      0.55      0.68       308\n",
            "          36       0.00      0.00      0.00        18\n",
            "          37       1.00      0.14      0.25        21\n",
            "          38       0.80      0.33      0.47        12\n",
            "          39       0.50      0.08      0.13        39\n",
            "          40       0.62      0.19      0.29        83\n",
            "          41       0.00      0.00      0.00         0\n",
            "          42       0.00      0.00      0.00        11\n",
            "          43       1.00      0.12      0.21        26\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       0.97      0.45      0.61       164\n",
            "          46       0.67      0.29      0.40         7\n",
            "          47       0.69      0.25      0.37       158\n",
            "          48       1.00      0.26      0.42        19\n",
            "          49       0.60      0.18      0.28       137\n",
            "          50       0.62      0.22      0.32       133\n",
            "          51       0.73      0.70      0.71       480\n",
            "          52       0.00      0.00      0.00        12\n",
            "          53       0.79      0.63      0.70       604\n",
            "          54       0.74      0.55      0.63       513\n",
            "          55       0.80      0.90      0.85       996\n",
            "\n",
            "   micro avg       0.78      0.58      0.67      6400\n",
            "   macro avg       0.50      0.20      0.26      6400\n",
            "weighted avg       0.76      0.58      0.63      6400\n",
            " samples avg       0.74      0.58      0.63      6400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx8T3O4Vg5vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_re = mlb.inverse_transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K36L7hrfmiz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_re = mlb.inverse_transform(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBGCEvIPBQYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_table = pd.DataFrame({'Predicted':y_pred_re,'Actual':y_test_re})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RdkqFUZBh_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "093c457a-2015-4979-93b3-2ed7a1c4a61e"
      },
      "source": [
        "label_table.head(6)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(35, Aries, Technology, male)</td>\n",
              "      <td>(35, Aries, Technology, male)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(36, Aries, Fashion, male)</td>\n",
              "      <td>(36, Aries, Fashion, male)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(female,)</td>\n",
              "      <td>(17, Scorpio, female, indUnk)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(female,)</td>\n",
              "      <td>(15, Libra, Student, female)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(17, Libra, Scorpio, female, indUnk)</td>\n",
              "      <td>(17, Scorpio, female, indUnk)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(27, 33, Aquarius, InvestmentBanking, Taurus, ...</td>\n",
              "      <td>(33, Aquarius, InvestmentBanking, male)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Predicted                                   Actual\n",
              "0                      (35, Aries, Technology, male)            (35, Aries, Technology, male)\n",
              "1                         (36, Aries, Fashion, male)               (36, Aries, Fashion, male)\n",
              "2                                          (female,)            (17, Scorpio, female, indUnk)\n",
              "3                                          (female,)             (15, Libra, Student, female)\n",
              "4               (17, Libra, Scorpio, female, indUnk)            (17, Scorpio, female, indUnk)\n",
              "5  (27, 33, Aquarius, InvestmentBanking, Taurus, ...  (33, Aquarius, InvestmentBanking, male)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMReZ8jGX0HK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "55b04bb1-a36b-4662-ef8b-cbc3a7dc9267"
      },
      "source": [
        "clfm.fit(x_train,y_train)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
              "                                            fit_prior=True),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JefAPHALX_21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predm = clfm.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UleH4M-kX-1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7542c2f3-b693-4f63-92bb-ab7d62fe465f"
      },
      "source": [
        "from sklearn.metrics import hamming_loss, accuracy_score,classification_report\n",
        "print(\"Model accuracy is:\", clfm.score(x_train,y_train))\n",
        "print(\"Accuracy is:\",accuracy_score(y_test,y_predm))\n",
        "print(\"Hamming_loss:\", hamming_loss(y_test, y_predm))\n",
        "reportm = classification_report(y_test,y_predm)\n",
        "print(reportm)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy is: 0.7926339285714286\n",
            "Accuracy is: 0.0725\n",
            "Hamming_loss: 0.05223214285714286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       1.00      0.06      0.11        36\n",
            "           2       0.00      0.00      0.00        93\n",
            "           3       0.00      0.00      0.00        11\n",
            "           4       1.00      0.03      0.06       181\n",
            "           5       0.00      0.00      0.00        42\n",
            "           6       0.50      0.02      0.03        66\n",
            "           7       0.00      0.00      0.00        57\n",
            "           8       0.00      0.00      0.00        19\n",
            "           9       1.00      0.02      0.05       123\n",
            "          10       0.00      0.00      0.00        17\n",
            "          11       1.00      0.03      0.05       108\n",
            "          12       0.98      0.09      0.16       473\n",
            "          13       0.93      0.20      0.33       328\n",
            "          14       0.00      0.00      0.00         7\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.00      0.00      0.00        18\n",
            "          17       0.00      0.00      0.00         3\n",
            "          18       0.00      0.00      0.00         2\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       1.00      0.01      0.03        71\n",
            "          24       0.92      0.44      0.59       832\n",
            "          25       0.00      0.00      0.00         5\n",
            "          26       0.00      0.00      0.00         5\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00        22\n",
            "          29       1.00      0.02      0.04        45\n",
            "          30       1.00      0.05      0.10        19\n",
            "          31       0.00      0.00      0.00        14\n",
            "          32       0.00      0.00      0.00         3\n",
            "          33       0.00      0.00      0.00        23\n",
            "          34       0.00      0.00      0.00        16\n",
            "          35       0.96      0.21      0.35       308\n",
            "          36       0.00      0.00      0.00        18\n",
            "          37       0.00      0.00      0.00        21\n",
            "          38       0.00      0.00      0.00        12\n",
            "          39       0.00      0.00      0.00        39\n",
            "          40       0.00      0.00      0.00        83\n",
            "          41       0.00      0.00      0.00         0\n",
            "          42       0.00      0.00      0.00        11\n",
            "          43       0.00      0.00      0.00        26\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       1.00      0.02      0.04       164\n",
            "          46       0.00      0.00      0.00         7\n",
            "          47       0.83      0.03      0.06       158\n",
            "          48       1.00      0.05      0.10        19\n",
            "          49       1.00      0.01      0.01       137\n",
            "          50       0.75      0.02      0.04       133\n",
            "          51       0.97      0.08      0.15       480\n",
            "          52       0.00      0.00      0.00        12\n",
            "          53       0.74      0.77      0.76       604\n",
            "          54       0.77      0.44      0.56       513\n",
            "          55       0.86      0.84      0.85       996\n",
            "\n",
            "   micro avg       0.84      0.33      0.48      6400\n",
            "   macro avg       0.34      0.06      0.08      6400\n",
            "weighted avg       0.81      0.33      0.39      6400\n",
            " samples avg       0.81      0.33      0.45      6400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPujlTkYndpO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "9df28675-5e7e-462a-d9d5-d0aa38b6b916"
      },
      "source": [
        "clf0.fit(x_train,y_train)\n",
        "print(\"This is the best score :\",clf0.best_score_)\n",
        "print(\"This are the best parameters:\",clf0.best_params_)\n",
        "print(\"This is the best estimator:\",clf0.best_estimator_)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the best score : 0.4794642857142857\n",
            "This are the best parameters: {'max_depth': 80}\n",
            "This is the best estimator: DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=80, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIvQPsuk5iMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ea83ba9a-ff38-4619-d705-b3a7d1cec9af"
      },
      "source": [
        "lr0 = clf0.best_estimator_\n",
        "lr0.fit(x_train,y_train)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=80, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyHeYubfuZis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred0 = lr0.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ9Y9wQduaL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5215c865-3a13-4dfa-83cc-4da98dfc20e4"
      },
      "source": [
        "from sklearn.metrics import hamming_loss, accuracy_score,classification_report\n",
        "print(\"Model accuracy is:\", lr0.score(x_train,y_train))\n",
        "print(\"Accuracy is:\",accuracy_score(y_test,y_pred0))\n",
        "print(\"Hamming_loss:\", hamming_loss(y_test, y_pred0))\n",
        "report0 = classification_report(y_test,y_pred0)\n",
        "print(report0)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy is: 0.9401785714285714\n",
            "Accuracy is: 0.4775\n",
            "Hamming_loss: 0.05924107142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.15      0.17      0.16        36\n",
            "           2       0.16      0.10      0.12        93\n",
            "           3       0.09      0.09      0.09        11\n",
            "           4       0.35      0.35      0.35       181\n",
            "           5       0.22      0.19      0.21        42\n",
            "           6       0.28      0.15      0.20        66\n",
            "           7       0.16      0.07      0.10        57\n",
            "           8       0.00      0.00      0.00        19\n",
            "           9       0.38      0.37      0.38       123\n",
            "          10       0.75      0.35      0.48        17\n",
            "          11       0.93      0.76      0.84       108\n",
            "          12       0.56      0.81      0.66       473\n",
            "          13       0.64      0.54      0.59       328\n",
            "          14       0.00      0.00      0.00         7\n",
            "          15       0.50      0.56      0.53         9\n",
            "          16       0.00      0.00      0.00        18\n",
            "          17       0.00      0.00      0.00         3\n",
            "          18       0.00      0.00      0.00         2\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.30      0.17      0.22        71\n",
            "          24       0.69      0.80      0.74       832\n",
            "          25       0.25      0.20      0.22         5\n",
            "          26       0.14      0.20      0.17         5\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.60      0.14      0.22        22\n",
            "          29       0.41      0.36      0.38        45\n",
            "          30       0.22      0.11      0.14        19\n",
            "          31       0.00      0.00      0.00        14\n",
            "          32       0.00      0.00      0.00         3\n",
            "          33       0.17      0.09      0.11        23\n",
            "          34       0.25      0.12      0.17        16\n",
            "          35       0.64      0.55      0.59       308\n",
            "          36       0.00      0.00      0.00        18\n",
            "          37       0.36      0.24      0.29        21\n",
            "          38       0.86      0.50      0.63        12\n",
            "          39       0.00      0.00      0.00        39\n",
            "          40       0.22      0.17      0.19        83\n",
            "          41       0.00      0.00      0.00         0\n",
            "          42       0.00      0.00      0.00        11\n",
            "          43       0.25      0.12      0.16        26\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       0.71      0.57      0.63       164\n",
            "          46       0.00      0.00      0.00         7\n",
            "          47       0.26      0.26      0.26       158\n",
            "          48       0.22      0.11      0.14        19\n",
            "          49       0.20      0.15      0.17       137\n",
            "          50       0.37      0.35      0.36       133\n",
            "          51       0.56      0.80      0.66       480\n",
            "          52       0.00      0.00      0.00        12\n",
            "          53       0.67      0.59      0.62       604\n",
            "          54       0.60      0.54      0.57       513\n",
            "          55       0.77      0.82      0.79       996\n",
            "\n",
            "   micro avg       0.59      0.59      0.59      6400\n",
            "   macro avg       0.27      0.22      0.23      6400\n",
            "weighted avg       0.57      0.59      0.57      6400\n",
            " samples avg       0.59      0.59      0.59      6400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXIco6FbuoAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_re0 = mlb.inverse_transform(y_pred0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeTueNCNussT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_table0 = pd.DataFrame({'Predicted':y_pred_re0,'Actual':y_test_re})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpRI4C4rxv03",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "74a6ebfc-17e2-45e5-ffaa-a86240cb28d1"
      },
      "source": [
        "label_table0.head(6)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(35, Aries, Technology, male)</td>\n",
              "      <td>(35, Aries, Technology, male)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(36, Aries, Fashion, male)</td>\n",
              "      <td>(36, Aries, Fashion, male)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(36, Aries, Fashion, male)</td>\n",
              "      <td>(17, Scorpio, female, indUnk)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(36, Aries, Fashion, male)</td>\n",
              "      <td>(15, Libra, Student, female)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(36, Aries, Fashion, male)</td>\n",
              "      <td>(17, Scorpio, female, indUnk)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(33, Aquarius, InvestmentBanking, male)</td>\n",
              "      <td>(33, Aquarius, InvestmentBanking, male)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Predicted                                   Actual\n",
              "0            (35, Aries, Technology, male)            (35, Aries, Technology, male)\n",
              "1               (36, Aries, Fashion, male)               (36, Aries, Fashion, male)\n",
              "2               (36, Aries, Fashion, male)            (17, Scorpio, female, indUnk)\n",
              "3               (36, Aries, Fashion, male)             (15, Libra, Student, female)\n",
              "4               (36, Aries, Fashion, male)            (17, Scorpio, female, indUnk)\n",
              "5  (33, Aquarius, InvestmentBanking, male)  (33, Aquarius, InvestmentBanking, male)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEqHmuLnIWgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "858725cd-eaf2-4f5f-bdd5-b5effe0a722c"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4480, 303947)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w31hp3wpIY-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "941fe2fc-a5b0-4875-8b96-07e14c23b42a"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4480, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8r019Ek1I4MS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b84e888f-d4b8-4e38-8b80-9ca270345596"
      },
      "source": [
        "clf1.fit(x_train,y_train)\n",
        "print(\"This is the best score :\",clf1.best_score_)\n",
        "print(\"This are the best parameters:\",clf1.best_params_)\n",
        "print(\"This is the best estimator:\",clf1.best_estimator_)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the best score : 0.07611607142857144\n",
            "This are the best parameters: {'n_neighbors': 5}\n",
            "This is the best estimator: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJgcfnKhKhFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d3b43696-8282-40fc-a1f8-af75ba5b4ef7"
      },
      "source": [
        "lr1 = clf1.best_estimator_\n",
        "lr1.fit(x_train,y_train)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jfbe_rfqI3yr",
        "colab": {}
      },
      "source": [
        "y_pred1 = lr1.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LmUS4OsqI3VA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5635e194-9228-4aae-dfd7-0784be84f0ec"
      },
      "source": [
        "from sklearn.metrics import hamming_loss, accuracy_score,classification_report\n",
        "print(\"Model accuracy is:\", lr1.score(x_train,y_train))\n",
        "print(\"Accuracy is:\",accuracy_score(y_test,y_pred1))\n",
        "print(\"Hamming_loss:\", hamming_loss(y_test, y_pred1))\n",
        "report1 = classification_report(y_test,y_pred1)\n",
        "print(report1)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy is: 0.17700892857142858\n",
            "Accuracy is: 0.081875\n",
            "Hamming_loss: 0.09214285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00        36\n",
            "           2       0.00      0.00      0.00        93\n",
            "           3       0.00      0.00      0.00        11\n",
            "           4       0.11      0.35      0.16       181\n",
            "           5       0.50      0.10      0.16        42\n",
            "           6       1.00      0.02      0.03        66\n",
            "           7       0.00      0.00      0.00        57\n",
            "           8       0.00      0.00      0.00        19\n",
            "           9       0.33      0.02      0.05       123\n",
            "          10       0.00      0.00      0.00        17\n",
            "          11       0.00      0.00      0.00       108\n",
            "          12       0.17      0.13      0.14       473\n",
            "          13       0.55      0.07      0.13       328\n",
            "          14       0.00      0.00      0.00         7\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.00      0.00      0.00        18\n",
            "          17       0.00      0.00      0.00         3\n",
            "          18       0.00      0.00      0.00         2\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.00      0.00      0.00        71\n",
            "          24       0.47      0.39      0.42       832\n",
            "          25       0.00      0.00      0.00         5\n",
            "          26       0.00      0.00      0.00         5\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       1.00      0.05      0.09        22\n",
            "          29       1.00      0.04      0.09        45\n",
            "          30       0.00      0.00      0.00        19\n",
            "          31       0.00      0.00      0.00        14\n",
            "          32       0.00      0.00      0.00         3\n",
            "          33       0.00      0.00      0.00        23\n",
            "          34       0.00      0.00      0.00        16\n",
            "          35       0.51      0.07      0.12       308\n",
            "          36       0.00      0.00      0.00        18\n",
            "          37       0.00      0.00      0.00        21\n",
            "          38       0.00      0.00      0.00        12\n",
            "          39       0.00      0.00      0.00        39\n",
            "          40       0.25      0.02      0.04        83\n",
            "          41       0.00      0.00      0.00         0\n",
            "          42       0.00      0.00      0.00        11\n",
            "          43       0.00      0.00      0.00        26\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       0.38      0.02      0.03       164\n",
            "          46       0.00      0.00      0.00         7\n",
            "          47       0.10      0.35      0.16       158\n",
            "          48       0.00      0.00      0.00        19\n",
            "          49       0.00      0.00      0.00       137\n",
            "          50       0.33      0.02      0.04       133\n",
            "          51       0.17      0.13      0.15       480\n",
            "          52       0.00      0.00      0.00        12\n",
            "          53       0.34      0.46      0.39       604\n",
            "          54       0.28      0.39      0.33       513\n",
            "          55       0.59      0.47      0.52       996\n",
            "\n",
            "   micro avg       0.31      0.25      0.28      6400\n",
            "   macro avg       0.14      0.06      0.05      6400\n",
            "weighted avg       0.34      0.25      0.25      6400\n",
            " samples avg       0.36      0.25      0.28      6400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZCOO-PJxBSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_re1 = mlb.inverse_transform(y_pred1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJtEWEeBxF9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_table1 = pd.DataFrame({'Predicted':y_pred_re1,'Actual':y_test_re})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa_QitvZuSOv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "53964058-d9f6-4540-fd0d-21beb59454a8"
      },
      "source": [
        "clf2.fit(x_train,y_train)\n",
        "print(\"This is the best score :\",clf2.best_score_)\n",
        "print(\"This are the best parameters:\",clf2.best_params_)\n",
        "print(\"This is the best estimator:\",clf2.best_estimator_)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the best score : 0.2571428571428571\n",
            "This are the best parameters: {'max_depth': 500}\n",
            "This is the best estimator: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=500, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0_s9qY_vnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "7e2ea722-4578-463f-9364-92c32bea23a2"
      },
      "source": [
        "lr2 = clf2.best_estimator_\n",
        "lr2.fit(x_train,y_train)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=500, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCy76s3jxOO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred2 = lr2.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcvg1JctxOJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1836ac0-6ba0-4cbd-e6b4-6d0e7b9a71b6"
      },
      "source": [
        "from sklearn.metrics import hamming_loss, accuracy_score,classification_report\n",
        "print(\"Model accuracy is:\", lr2.score(x_train,y_train))\n",
        "print(\"Accuracy is:\",accuracy_score(y_test,y_pred2))\n",
        "print(\"Hamming_loss:\", hamming_loss(y_test, y_pred2))\n",
        "report2 = classification_report(y_test,y_pred2)\n",
        "print(report2)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy is: 0.9859375\n",
            "Accuracy is: 0.278125\n",
            "Hamming_loss: 0.05368303571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       1.00      0.03      0.05        36\n",
            "           2       0.00      0.00      0.00        93\n",
            "           3       0.00      0.00      0.00        11\n",
            "           4       1.00      0.02      0.03       181\n",
            "           5       0.00      0.00      0.00        42\n",
            "           6       0.00      0.00      0.00        66\n",
            "           7       0.00      0.00      0.00        57\n",
            "           8       0.00      0.00      0.00        19\n",
            "           9       0.00      0.00      0.00       123\n",
            "          10       0.00      0.00      0.00        17\n",
            "          11       0.88      0.06      0.12       108\n",
            "          12       0.64      0.78      0.70       473\n",
            "          13       0.95      0.22      0.36       328\n",
            "          14       0.00      0.00      0.00         7\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.00      0.00      0.00        18\n",
            "          17       0.00      0.00      0.00         3\n",
            "          18       0.00      0.00      0.00         2\n",
            "          19       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       1.00      0.01      0.03        71\n",
            "          24       0.66      0.93      0.77       832\n",
            "          25       0.00      0.00      0.00         5\n",
            "          26       0.00      0.00      0.00         5\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00        22\n",
            "          29       1.00      0.02      0.04        45\n",
            "          30       1.00      0.05      0.10        19\n",
            "          31       0.00      0.00      0.00        14\n",
            "          32       0.00      0.00      0.00         3\n",
            "          33       0.00      0.00      0.00        23\n",
            "          34       0.00      0.00      0.00        16\n",
            "          35       1.00      0.22      0.36       308\n",
            "          36       0.00      0.00      0.00        18\n",
            "          37       0.00      0.00      0.00        21\n",
            "          38       0.00      0.00      0.00        12\n",
            "          39       0.00      0.00      0.00        39\n",
            "          40       0.00      0.00      0.00        83\n",
            "          41       0.00      0.00      0.00         0\n",
            "          42       0.00      0.00      0.00        11\n",
            "          43       0.00      0.00      0.00        26\n",
            "          44       0.00      0.00      0.00         1\n",
            "          45       0.88      0.04      0.08       164\n",
            "          46       0.00      0.00      0.00         7\n",
            "          47       0.00      0.00      0.00       158\n",
            "          48       1.00      0.05      0.10        19\n",
            "          49       0.00      0.00      0.00       137\n",
            "          50       0.00      0.00      0.00       133\n",
            "          51       0.64      0.78      0.70       480\n",
            "          52       0.00      0.00      0.00        12\n",
            "          53       0.82      0.30      0.44       604\n",
            "          54       0.77      0.17      0.28       513\n",
            "          55       0.70      0.95      0.81       996\n",
            "\n",
            "   micro avg       0.69      0.45      0.55      6400\n",
            "   macro avg       0.25      0.08      0.09      6400\n",
            "weighted avg       0.62      0.45      0.44      6400\n",
            " samples avg       0.65      0.45      0.51      6400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVKHTMrVxOGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_re2 = mlb.inverse_transform(y_pred2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRF6zJbnxapg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_table2 = pd.DataFrame({'Predicted':y_pred_re2,'Actual':y_test_re})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74zkpxmcCjNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "9651e7b5-2375-4498-fa51-76a51a372451"
      },
      "source": [
        "label_table2.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(35, Aries, Technology, male)</td>\n",
              "      <td>(35, Aries, Technology, male)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(36, Aries, Fashion, male)</td>\n",
              "      <td>(36, Aries, Fashion, male)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Aries, male)</td>\n",
              "      <td>(17, Scorpio, female, indUnk)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(male,)</td>\n",
              "      <td>(15, Libra, Student, female)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(male,)</td>\n",
              "      <td>(17, Scorpio, female, indUnk)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Predicted                         Actual\n",
              "0  (35, Aries, Technology, male)  (35, Aries, Technology, male)\n",
              "1     (36, Aries, Fashion, male)     (36, Aries, Fashion, male)\n",
              "2                  (Aries, male)  (17, Scorpio, female, indUnk)\n",
              "3                        (male,)   (15, Libra, Student, female)\n",
              "4                        (male,)  (17, Scorpio, female, indUnk)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLa6yRMvkP2Q",
        "colab_type": "text"
      },
      "source": [
        "Conclusion : - The model accuracy or accuracy achieved in training the models is quite good but when these models are put to test they don't perform that well.Among these classifiers the Decision tree gives a better accuracy wwhereas a random forest & Multinomial shows better Micro,Macro,weighted average scores for precision,recall & ofcourse F1-score.Some more techniques can help us understand & get a better accuracy on the test as well.\n",
        "\n"
      ]
    }
  ]
}