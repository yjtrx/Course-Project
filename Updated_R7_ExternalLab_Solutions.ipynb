{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Updated_R7_ExternalLab_Solutions.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4WH1Pr4KQlCh","colab_type":"text"},"source":["### Build a DNN using Keras with `RELU` and `ADAM`"]},{"cell_type":"markdown","metadata":{"id":"TbvI8LqlQlCl","colab_type":"text"},"source":["#### Load tensorflow"]},{"cell_type":"code","metadata":{"id":"3bt41xOW9ulz","colab_type":"code","outputId":"8d8d7873-5917-40bd-9f4c-e93f081fcf49","executionInfo":{"status":"ok","timestamp":1579865423430,"user_tz":-330,"elapsed":1009,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Using tensorflow version 2 since 1 is supposedly going to be deprecated\n","%tensorflow_version 2.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SPW-a-qYQlCp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"700d1b99-c7e1-4912-af49-723583af87bd","executionInfo":{"status":"ok","timestamp":1579865547158,"user_tz":-330,"elapsed":1935,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}}},"source":["print(\"Importing tensorflow...\")\n","import tensorflow as tf"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Importing tensorflow...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M2-ePqNsC2eR","colab_type":"code","outputId":"d4e8c360-8d41-4c64-e044-c4847153a9a9","executionInfo":{"status":"ok","timestamp":1579865555742,"user_tz":-330,"elapsed":1032,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Checking if the selected tensorflow version is ==>> \",tf.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Checking if the selected tensorflow version is ==>>  2.1.0-rc1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"74cQBsi5QlCw","colab_type":"text"},"source":["#### Collect Fashion mnist data from tf.keras.datasets "]},{"cell_type":"code","metadata":{"id":"wVWy0oDTr2Kj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c7397f62-e505-4ad3-dca3-4e9df2ab2ffc","executionInfo":{"status":"ok","timestamp":1579865638117,"user_tz":-330,"elapsed":1000,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}}},"source":["mnist = tf.keras.datasets.fashion_mnist\n","print(\"Getting the data from the keras module....\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Getting the data from the keras module....\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eSp3lEpgDTzz","colab_type":"code","outputId":"0ddfe050-e19c-49f9-a3b8-330f4fafd9d8","executionInfo":{"status":"ok","timestamp":1579865717159,"user_tz":-330,"elapsed":1361,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["print(\"Loading the data directly into train & test sets\")\n","(x_train,y_train),(x_test,y_test) = mnist.load_data()\n","print(\"Checking the shape of train & test datasets..\")\n","print(\"The shape of x_train is ==>>\",x_train.shape)\n","print(\"The shape of x_test is ==>>\",x_test.shape)\n","print(\"The shape of y_train is ==>>\",y_train.shape)\n","print(\"The shape of y_test is ==>>\",y_test.shape)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Loading the data directly into train & test sets\n","Checking the shape of train & test datasets..\n","The shape of x_train is ==>> (60000, 28, 28)\n","The shape of x_test is ==>> (10000, 28, 28)\n","The shape of y_train is ==>> (60000,)\n","The shape of y_test is ==>> (10000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dc443Zw1aeST","colab_type":"code","outputId":"5143068b-ef6c-4bfd-d63d-628ad0579029","executionInfo":{"status":"ok","timestamp":1579865956644,"user_tz":-330,"elapsed":973,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["print(\"Importing numpy..\")\n","import numpy as np\n","print(\"Checking the data-range present in image which seems to be having \\n{} values.\".format(np.unique(x_train[0])))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Importing numpy..\n","Checking the data-range present in image which seems to be having \n","[  0   1   2   3   4   6   7  10  12  13  15  18  23  29  35  36  40  41\n","  44  48  52  54  55  56  57  58  61  62  64  65  66  67  69  72  73  74\n","  75  77  80  82  88  92  98  99 102 106 107 109 115 117 119 121 122 123\n"," 127 130 134 136 141 144 145 146 150 154 155 156 159 161 163 164 166 167\n"," 168 169 170 171 172 173 175 176 177 178 179 180 181 182 183 185 186 187\n"," 188 189 190 191 192 193 194 195 196 197 198 199 200 202 203 204 205 206\n"," 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n"," 225 226 227 228 229 230 232 233 234 235 236 237 238 239 240 241 242 243\n"," 244 245 246 248 249 250 255] values.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"khreW1XnizTS","colab_type":"code","outputId":"df06fb3f-485e-4c18-f1bb-c625ebf1f5d2","executionInfo":{"status":"ok","timestamp":1579867463901,"user_tz":-330,"elapsed":1088,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(\"Checking the values in the first image :\")\n","x_train[0]"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Checking the values in the first image :\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n","          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n","          1,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n","          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n","          0,   3],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n","          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n","         10,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n","         72,  15],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n","         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n","        172,  66],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n","        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n","        229,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n","        173,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n","        202,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n","        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n","        209,  52],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n","        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n","        167,  56],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n","        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n","         92,   0],\n","       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n","        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n","         77,   0],\n","       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n","        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n","        159,   0],\n","       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n","        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n","        215,   0],\n","       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n","        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n","        246,   0],\n","       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n","         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n","        225,   0],\n","       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n","        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n","        229,  29],\n","       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n","        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n","        230,  67],\n","       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n","        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n","        206, 115],\n","       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n","        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n","        210,  92],\n","       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n","        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n","        170,   0],\n","       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n","        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"no7aWYZyQlC1","colab_type":"text"},"source":["#### Change train and test labels into one-hot vectors"]},{"cell_type":"code","metadata":{"id":"UryhjHlYEjnu","colab_type":"code","outputId":"e743232e-a73c-4cce-e231-8d07fff7d62d","executionInfo":{"status":"ok","timestamp":1579867987121,"user_tz":-330,"elapsed":988,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["print(\"Checking the values present in the labels..\")\n","tf.unique(y_train)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Checking the values present in the labels..\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Unique(y=<tf.Tensor: shape=(10,), dtype=uint8, numpy=array([9, 0, 3, 2, 7, 5, 1, 6, 4, 8], dtype=uint8)>, idx=<tf.Tensor: shape=(60000,), dtype=int32, numpy=array([0, 1, 1, ..., 2, 1, 5], dtype=int32)>)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"UX6otc4wQlC2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c64fafb5-d9c6-4207-bb26-f86718cca528","executionInfo":{"status":"ok","timestamp":1579867987787,"user_tz":-330,"elapsed":702,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}}},"source":["print(\"Encoding the train label into one-hot vector\")\n","y_train_enc = tf.keras.utils.to_categorical(y_train,num_classes=10)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Encoding the train label into one-hot vector\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gwoHm8CRGrv1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"53ffd7fa-5a4c-49e9-b198-fa0b1a9fbfae","executionInfo":{"status":"ok","timestamp":1579867988504,"user_tz":-330,"elapsed":867,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}}},"source":["print(\"Encoding the test label into one-hot vector\")\n","y_test_enc = tf.keras.utils.to_categorical(y_test,num_classes=10)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Encoding the test label into one-hot vector\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QjNrRTdoQlC5","colab_type":"text"},"source":["#### Build the Graph"]},{"cell_type":"markdown","metadata":{"id":"CDJ9DHVNQlC7","colab_type":"text"},"source":["#### Initialize model, reshape & normalize data"]},{"cell_type":"code","metadata":{"id":"mvi2FljoN4RP","colab_type":"code","outputId":"8a9eaef1-ba62-48ed-c715-9d822cf642a1","executionInfo":{"status":"ok","timestamp":1579868148991,"user_tz":-330,"elapsed":975,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_train.shape"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"pCDQs_g1QlC8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"740926b8-3bbc-4f48-a131-83dc668fa2f7","executionInfo":{"status":"ok","timestamp":1579868266523,"user_tz":-330,"elapsed":1017,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}}},"source":["print(\"Import models module from keras.. \\nImporting layers module from keras..\")\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","print(\"Normalizing the data\")\n","x_train_norm = x_train/255\n","x_test_norm = x_test/255\n","print(\"Reshaping the model as well as initializing the model\")\n","model = models.Sequential([layers.Flatten(input_shape=(28,28))])"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Import models module from keras.. \n","Importing layers module from keras..\n","Normalizing the data\n","Reshaping the model as well as initializing the model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0g-XKDpmYyg5","colab_type":"code","outputId":"fb6d0cf2-9538-4627-ac4f-e3493dc49af6","executionInfo":{"status":"ok","timestamp":1579868285987,"user_tz":-330,"elapsed":3057,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":933}},"source":["print(\"Checking the values\")\n","import numpy as np\n","np.unique(x_train_norm)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Checking the values\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([0.        , 0.00392157, 0.00784314, 0.01176471, 0.01568627,\n","       0.01960784, 0.02352941, 0.02745098, 0.03137255, 0.03529412,\n","       0.03921569, 0.04313725, 0.04705882, 0.05098039, 0.05490196,\n","       0.05882353, 0.0627451 , 0.06666667, 0.07058824, 0.0745098 ,\n","       0.07843137, 0.08235294, 0.08627451, 0.09019608, 0.09411765,\n","       0.09803922, 0.10196078, 0.10588235, 0.10980392, 0.11372549,\n","       0.11764706, 0.12156863, 0.1254902 , 0.12941176, 0.13333333,\n","       0.1372549 , 0.14117647, 0.14509804, 0.14901961, 0.15294118,\n","       0.15686275, 0.16078431, 0.16470588, 0.16862745, 0.17254902,\n","       0.17647059, 0.18039216, 0.18431373, 0.18823529, 0.19215686,\n","       0.19607843, 0.2       , 0.20392157, 0.20784314, 0.21176471,\n","       0.21568627, 0.21960784, 0.22352941, 0.22745098, 0.23137255,\n","       0.23529412, 0.23921569, 0.24313725, 0.24705882, 0.25098039,\n","       0.25490196, 0.25882353, 0.2627451 , 0.26666667, 0.27058824,\n","       0.2745098 , 0.27843137, 0.28235294, 0.28627451, 0.29019608,\n","       0.29411765, 0.29803922, 0.30196078, 0.30588235, 0.30980392,\n","       0.31372549, 0.31764706, 0.32156863, 0.3254902 , 0.32941176,\n","       0.33333333, 0.3372549 , 0.34117647, 0.34509804, 0.34901961,\n","       0.35294118, 0.35686275, 0.36078431, 0.36470588, 0.36862745,\n","       0.37254902, 0.37647059, 0.38039216, 0.38431373, 0.38823529,\n","       0.39215686, 0.39607843, 0.4       , 0.40392157, 0.40784314,\n","       0.41176471, 0.41568627, 0.41960784, 0.42352941, 0.42745098,\n","       0.43137255, 0.43529412, 0.43921569, 0.44313725, 0.44705882,\n","       0.45098039, 0.45490196, 0.45882353, 0.4627451 , 0.46666667,\n","       0.47058824, 0.4745098 , 0.47843137, 0.48235294, 0.48627451,\n","       0.49019608, 0.49411765, 0.49803922, 0.50196078, 0.50588235,\n","       0.50980392, 0.51372549, 0.51764706, 0.52156863, 0.5254902 ,\n","       0.52941176, 0.53333333, 0.5372549 , 0.54117647, 0.54509804,\n","       0.54901961, 0.55294118, 0.55686275, 0.56078431, 0.56470588,\n","       0.56862745, 0.57254902, 0.57647059, 0.58039216, 0.58431373,\n","       0.58823529, 0.59215686, 0.59607843, 0.6       , 0.60392157,\n","       0.60784314, 0.61176471, 0.61568627, 0.61960784, 0.62352941,\n","       0.62745098, 0.63137255, 0.63529412, 0.63921569, 0.64313725,\n","       0.64705882, 0.65098039, 0.65490196, 0.65882353, 0.6627451 ,\n","       0.66666667, 0.67058824, 0.6745098 , 0.67843137, 0.68235294,\n","       0.68627451, 0.69019608, 0.69411765, 0.69803922, 0.70196078,\n","       0.70588235, 0.70980392, 0.71372549, 0.71764706, 0.72156863,\n","       0.7254902 , 0.72941176, 0.73333333, 0.7372549 , 0.74117647,\n","       0.74509804, 0.74901961, 0.75294118, 0.75686275, 0.76078431,\n","       0.76470588, 0.76862745, 0.77254902, 0.77647059, 0.78039216,\n","       0.78431373, 0.78823529, 0.79215686, 0.79607843, 0.8       ,\n","       0.80392157, 0.80784314, 0.81176471, 0.81568627, 0.81960784,\n","       0.82352941, 0.82745098, 0.83137255, 0.83529412, 0.83921569,\n","       0.84313725, 0.84705882, 0.85098039, 0.85490196, 0.85882353,\n","       0.8627451 , 0.86666667, 0.87058824, 0.8745098 , 0.87843137,\n","       0.88235294, 0.88627451, 0.89019608, 0.89411765, 0.89803922,\n","       0.90196078, 0.90588235, 0.90980392, 0.91372549, 0.91764706,\n","       0.92156863, 0.9254902 , 0.92941176, 0.93333333, 0.9372549 ,\n","       0.94117647, 0.94509804, 0.94901961, 0.95294118, 0.95686275,\n","       0.96078431, 0.96470588, 0.96862745, 0.97254902, 0.97647059,\n","       0.98039216, 0.98431373, 0.98823529, 0.99215686, 0.99607843,\n","       1.        ])"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"kBGwTTilQlDD","colab_type":"text"},"source":["#### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"]},{"cell_type":"code","metadata":{"id":"IXbfpfOzQlDF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3a46113f-4eb7-4c70-93b8-beb4573e1015","executionInfo":{"status":"ok","timestamp":1579868310354,"user_tz":-330,"elapsed":1057,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}}},"source":["print(\"Adding dropout layer at the beginning with 2 Dense layers having 200 & 100 neurons respectively.\")\n","model.add(layers.Dropout(0.25))\n","model.add(layers.Dense(200,activation = 'relu',input_shape=(28,28)))\n","model.add(layers.Dense(100,activation='relu'))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Adding dropout layer at the beginning with 2 Dense layers having 200 & 100 neurons respectively.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5I8f5otcQlDJ","colab_type":"text"},"source":["### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."]},{"cell_type":"code","metadata":{"id":"JZkvKymSd0Sr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"212e839b-aa5b-4bd4-85db-5c4a2ba1dd8d","executionInfo":{"status":"ok","timestamp":1579868332469,"user_tz":-330,"elapsed":1937,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}}},"source":["print(\"Adding the final/output layer\")\n","model.add(layers.Dense(10,activation = 'softmax'))\n","print(\"Compiling the model as per instructed\")\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics = ['accuracy'])"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Adding the final/output layer\n","Compiling the model as per instructed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"olnYepxggPxs","colab_type":"code","outputId":"6f1737c1-72ec-4bef-9c3e-a2ef20290bad","executionInfo":{"status":"ok","timestamp":1579868650432,"user_tz":-330,"elapsed":310317,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(\"Fitting the model to check how well it's reducing the loss\")\n","model.fit(x_train_norm,y_train_enc,epochs=50,validation_data=(x_test_norm,y_test_enc),batch_size=32)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Fitting the model to check how well it's reducing the loss\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 8s 131us/sample - loss: 0.5837 - accuracy: 0.7864 - val_loss: 0.4386 - val_accuracy: 0.8402\n","Epoch 2/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.4444 - accuracy: 0.8369 - val_loss: 0.4353 - val_accuracy: 0.8285\n","Epoch 3/50\n","60000/60000 [==============================] - 6s 100us/sample - loss: 0.4096 - accuracy: 0.8509 - val_loss: 0.3997 - val_accuracy: 0.8533\n","Epoch 4/50\n","60000/60000 [==============================] - 6s 101us/sample - loss: 0.3847 - accuracy: 0.8572 - val_loss: 0.3716 - val_accuracy: 0.8611\n","Epoch 5/50\n","60000/60000 [==============================] - 6s 97us/sample - loss: 0.3710 - accuracy: 0.8630 - val_loss: 0.3718 - val_accuracy: 0.8612\n","Epoch 6/50\n","60000/60000 [==============================] - 6s 99us/sample - loss: 0.3561 - accuracy: 0.8679 - val_loss: 0.3719 - val_accuracy: 0.8596\n","Epoch 7/50\n","60000/60000 [==============================] - 6s 102us/sample - loss: 0.3463 - accuracy: 0.8708 - val_loss: 0.3480 - val_accuracy: 0.8717\n","Epoch 8/50\n","60000/60000 [==============================] - 6s 102us/sample - loss: 0.3387 - accuracy: 0.8743 - val_loss: 0.3341 - val_accuracy: 0.8786\n","Epoch 9/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.3342 - accuracy: 0.8763 - val_loss: 0.3376 - val_accuracy: 0.8764\n","Epoch 10/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.3261 - accuracy: 0.8781 - val_loss: 0.3527 - val_accuracy: 0.8710\n","Epoch 11/50\n","60000/60000 [==============================] - 6s 100us/sample - loss: 0.3209 - accuracy: 0.8804 - val_loss: 0.3443 - val_accuracy: 0.8748\n","Epoch 12/50\n","60000/60000 [==============================] - 6s 101us/sample - loss: 0.3168 - accuracy: 0.8813 - val_loss: 0.3293 - val_accuracy: 0.8779\n","Epoch 13/50\n","60000/60000 [==============================] - 6s 100us/sample - loss: 0.3117 - accuracy: 0.8835 - val_loss: 0.3358 - val_accuracy: 0.8791\n","Epoch 14/50\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.3073 - accuracy: 0.8846 - val_loss: 0.3240 - val_accuracy: 0.8837\n","Epoch 15/50\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.2997 - accuracy: 0.8874 - val_loss: 0.3366 - val_accuracy: 0.8775\n","Epoch 16/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.3000 - accuracy: 0.8887 - val_loss: 0.3274 - val_accuracy: 0.8824\n","Epoch 17/50\n","60000/60000 [==============================] - 6s 105us/sample - loss: 0.2980 - accuracy: 0.8880 - val_loss: 0.3370 - val_accuracy: 0.8787\n","Epoch 18/50\n","60000/60000 [==============================] - 6s 102us/sample - loss: 0.2940 - accuracy: 0.8911 - val_loss: 0.3211 - val_accuracy: 0.8851\n","Epoch 19/50\n","60000/60000 [==============================] - 6s 102us/sample - loss: 0.2932 - accuracy: 0.8899 - val_loss: 0.3261 - val_accuracy: 0.8835\n","Epoch 20/50\n","60000/60000 [==============================] - 6s 101us/sample - loss: 0.2879 - accuracy: 0.8910 - val_loss: 0.3327 - val_accuracy: 0.8850\n","Epoch 21/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.2865 - accuracy: 0.8927 - val_loss: 0.3268 - val_accuracy: 0.8844\n","Epoch 22/50\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.2874 - accuracy: 0.8922 - val_loss: 0.3399 - val_accuracy: 0.8807\n","Epoch 23/50\n","60000/60000 [==============================] - 6s 105us/sample - loss: 0.2826 - accuracy: 0.8943 - val_loss: 0.3323 - val_accuracy: 0.8831\n","Epoch 24/50\n","60000/60000 [==============================] - 6s 105us/sample - loss: 0.2806 - accuracy: 0.8945 - val_loss: 0.3282 - val_accuracy: 0.8827\n","Epoch 25/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.2797 - accuracy: 0.8954 - val_loss: 0.3213 - val_accuracy: 0.8846\n","Epoch 26/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.2781 - accuracy: 0.8952 - val_loss: 0.3276 - val_accuracy: 0.8834\n","Epoch 27/50\n","60000/60000 [==============================] - 6s 101us/sample - loss: 0.2741 - accuracy: 0.8980 - val_loss: 0.3196 - val_accuracy: 0.8854\n","Epoch 28/50\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.2761 - accuracy: 0.8958 - val_loss: 0.3210 - val_accuracy: 0.8894\n","Epoch 29/50\n","60000/60000 [==============================] - 6s 100us/sample - loss: 0.2766 - accuracy: 0.8958 - val_loss: 0.3202 - val_accuracy: 0.8852\n","Epoch 30/50\n","60000/60000 [==============================] - 6s 101us/sample - loss: 0.2685 - accuracy: 0.8995 - val_loss: 0.3141 - val_accuracy: 0.8870\n","Epoch 31/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.2688 - accuracy: 0.8992 - val_loss: 0.3135 - val_accuracy: 0.8912\n","Epoch 32/50\n","60000/60000 [==============================] - 6s 102us/sample - loss: 0.2692 - accuracy: 0.8992 - val_loss: 0.3154 - val_accuracy: 0.8858\n","Epoch 33/50\n","60000/60000 [==============================] - 6s 102us/sample - loss: 0.2672 - accuracy: 0.9002 - val_loss: 0.3191 - val_accuracy: 0.8873\n","Epoch 34/50\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.2629 - accuracy: 0.9020 - val_loss: 0.3203 - val_accuracy: 0.8866\n","Epoch 35/50\n","60000/60000 [==============================] - 6s 105us/sample - loss: 0.2646 - accuracy: 0.9008 - val_loss: 0.3221 - val_accuracy: 0.8888\n","Epoch 36/50\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.2633 - accuracy: 0.9010 - val_loss: 0.3219 - val_accuracy: 0.8886\n","Epoch 37/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.2635 - accuracy: 0.9015 - val_loss: 0.3151 - val_accuracy: 0.8901\n","Epoch 38/50\n","60000/60000 [==============================] - 6s 102us/sample - loss: 0.2597 - accuracy: 0.9018 - val_loss: 0.3228 - val_accuracy: 0.8893\n","Epoch 39/50\n","60000/60000 [==============================] - 6s 100us/sample - loss: 0.2594 - accuracy: 0.9031 - val_loss: 0.3246 - val_accuracy: 0.8898\n","Epoch 40/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.2599 - accuracy: 0.9020 - val_loss: 0.3045 - val_accuracy: 0.8931\n","Epoch 41/50\n","60000/60000 [==============================] - 6s 103us/sample - loss: 0.2565 - accuracy: 0.9026 - val_loss: 0.3069 - val_accuracy: 0.8906\n","Epoch 42/50\n","60000/60000 [==============================] - 6s 101us/sample - loss: 0.2558 - accuracy: 0.9042 - val_loss: 0.3137 - val_accuracy: 0.8917\n","Epoch 43/50\n","60000/60000 [==============================] - 6s 105us/sample - loss: 0.2519 - accuracy: 0.9057 - val_loss: 0.3208 - val_accuracy: 0.8912\n","Epoch 44/50\n","60000/60000 [==============================] - 6s 101us/sample - loss: 0.2542 - accuracy: 0.9045 - val_loss: 0.3305 - val_accuracy: 0.8900\n","Epoch 45/50\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.2541 - accuracy: 0.9050 - val_loss: 0.3194 - val_accuracy: 0.8895\n","Epoch 46/50\n","60000/60000 [==============================] - 6s 104us/sample - loss: 0.2565 - accuracy: 0.9047 - val_loss: 0.3235 - val_accuracy: 0.8906\n","Epoch 47/50\n","60000/60000 [==============================] - 7s 111us/sample - loss: 0.2505 - accuracy: 0.9062 - val_loss: 0.3114 - val_accuracy: 0.8889\n","Epoch 48/50\n","60000/60000 [==============================] - 6s 107us/sample - loss: 0.2519 - accuracy: 0.9062 - val_loss: 0.3152 - val_accuracy: 0.8892\n","Epoch 49/50\n","60000/60000 [==============================] - 6s 101us/sample - loss: 0.2490 - accuracy: 0.9075 - val_loss: 0.3122 - val_accuracy: 0.8895\n","Epoch 50/50\n","60000/60000 [==============================] - 6s 101us/sample - loss: 0.2492 - accuracy: 0.9068 - val_loss: 0.3241 - val_accuracy: 0.8891\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f2c304cc2e8>"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"r-J9VmEmgyHG","colab_type":"code","outputId":"4998bfd0-c08d-4b00-e9c3-6db5f945be08","executionInfo":{"status":"ok","timestamp":1579868993744,"user_tz":-330,"elapsed":7047,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["print(\"Getting the final evaluation on train set\")\n","eval1 = model.evaluate(x_train_norm,y_train_enc)\n","print(\"The training loss is {}% & the training accuracy is {}% \".format(eval1[0]*100,eval1[1]*100))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Getting the final evaluation on train set\n","60000/60000 [==============================] - 4s 65us/sample - loss: 0.1977 - accuracy: 0.9262\n","The training loss is 19.770803134540717% & the training accuracy is 92.61833429336548% \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bHSXbQOMgXBr","colab_type":"code","outputId":"0651285f-7f03-482a-aa46-7c3d7e457e09","executionInfo":{"status":"ok","timestamp":1579868993745,"user_tz":-330,"elapsed":6537,"user":{"displayName":"yashraj tambe","photoUrl":"","userId":"12837507511175563418"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["print(\"Getting the final evaluation on test set\")\n","eval2 = model.evaluate(x_test_norm,y_test_enc)\n","print(\"The test loss is {}% & the test accuracy is {}% \".format(eval2[0]*100,eval2[1]*100))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Getting the final evaluation on test set\n","10000/10000 [==============================] - 1s 70us/sample - loss: 0.3241 - accuracy: 0.8891\n","The test loss is 32.405614990592% & the test accuracy is 88.91000151634216% \n"],"name":"stdout"}]}]}